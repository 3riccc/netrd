{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0: Welcome to `netrd`!\n",
    "## This notebook will detail the main tools and functionality of `netrd`\n",
    "\n",
    "Created by Brennan Klein: May 22nd, 2019. For questions, comments, concerns, and more, reach out at \n",
    "\n",
    "    brennanjamesklein at gmail dot com\n",
    "\n",
    "Note: Currently, the output of each cell is included as an inserted .png from the \"output_figures/\" folder for readability. When using this document, you will probably want to remove those markdown cells to create graphics of your own.\n",
    "\n",
    "### Other resources:\n",
    "- __[View this notebook on NBviewer](https://nbviewer.jupyter.org/github/jkbren/netrd/blob/master/notebooks/netrd_introduction.ipynb)__\n",
    "- __[Visit the github](https://github.com/netsiphd/netrd)__\n",
    "- __[Visit the ReadTheDocs](https://netrd.readthedocs.io/en/latest/)__\n",
    "- __[Visit the netrdExplorer website](https://netrdexplorer.herokuapp.com/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "**\"Comparing methods for reconstructing networks from time series data by comparing methods for measuring network similarity\"**\n",
    "\n",
    "Across many disciplines, we analyze networks that have been reconstructed or inferred from time series data (e.g., changes in brain activity in neuroscience, shifting stock prices in economics, population dynamics in ecology). These networks can be reconstructed using a variety of techniques, but because different algorithms can output different networks, practitioners are often uncertain about whether their approach is suitable for describing the system in question. Similar to other tools in network science, it appears that no single technique is universally optimal for inferring network structure from time series data. The absence of a \"best\" technique is likely due to several factors, from the quality or amount of time series data collected, to the nature of the system or dynamics being modeled, to the types of interactions between entities in the system (causal, correlational, weighted, etc.). \n",
    "\n",
    "In this work, we review dozens of network reconstruction techniques in order to characterize the extent to which different techniques will output networks that are similar to one another. The goal of this review is *not* to provide estimates of the \"best\" network reconstruction technique but rather to identify approaches that are more likely to infer similar network structures given the same time series data. In doing so, we also systematically compare a number of techniques for measuring network similarity or (also known as graph distance). By also releasing the methods implemented in this work as a software package, **`netrd`**, we hope this research will spur new insights about possible latent similarities between the mathematical, algorithmic, or theoretical aspects of different network reconstruction techniques and of different network similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netrd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from netrd.utilities import standardize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_savefigs_to = \"\"\n",
    "# folder_to_savefigs_to = \"output_figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1: Plotting and simulation functions (run these and continue below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groundtruth_timeseries_adjmat(G0, TS, \n",
    "                                       dyna_name='SherringtonKirkpatrickIsing', \n",
    "                                       colmap=plt.cm.Greys, save=True):\n",
    "    ns = 100\n",
    "    nc = 'w'\n",
    "    ec = '#333333'\n",
    "    oc = '#e4c600'\n",
    "    nc_o = '#333333'\n",
    "\n",
    "    plt.rc('axes', linewidth=2)\n",
    "    pos = nx.kamada_kawai_layout(G0)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(18,4))\n",
    "    gs      = gridspec.GridSpec(1, 3, width_ratios=[1, 2, 1]) \n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    nx.draw_networkx_nodes(G0, pos, node_size=ns, node_color=nc, \n",
    "                           linewidths=2.5, edgecolors=nc_o, ax=ax0)\n",
    "    nx.draw_networkx_edges(G0, pos, width=1.75,   edge_color=ec, \n",
    "                           alpha=0.5, ax=ax0)\n",
    "    ax0.set_title(\"Ground truth network\", size=14)\n",
    "    ax0.set_axis_off()\n",
    "\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    ax1.imshow(TS,cmap=plt.cm.Greys,aspect='auto')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel(\"Time\", size=14)\n",
    "    ax1.set_ylabel(\"Node ID\", size=14)\n",
    "    ax1.set_title(\"%s dynamics\"%dyna_name, size=14)\n",
    "\n",
    "    ax2 = plt.subplot(gs[2])\n",
    "    W0 = nx.to_numpy_array(G0)\n",
    "    ax2.pcolor(W0, cmap=plt.cm.Greys, edgecolors='w', linewidth=0.2)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_title('Ground truth adjacency matrix', size=14)\n",
    "\n",
    "    if save==True:\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleGroundTruth_%s.png\"%dyna_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleGroundTruth_%s.pdf\"%dyna_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)\n",
    "    \n",
    "def plot_adjmat_timeseries_recon(G0, TS, recons, \n",
    "                                 recon_name='FreeEnergyMinimization', \n",
    "                                 colmap=plt.cm.Greys,\n",
    "                                 save=True):\n",
    "    plt.rc('axes', linewidth=2)\n",
    "\n",
    "    W0 = nx.to_numpy_array(G0)\n",
    "    k_avg = np.mean(list(dict(G0.degree()).values()))\n",
    "    ### Reconstruct the network and turn it into an adjacency matrix ###\n",
    "    R1 = recons[recon_name]\n",
    "    Gr = R1.fit(TS, threshold_type='degree', avg_k=k_avg)\n",
    "    Wr = nx.to_numpy_array(Gr)\n",
    "    \n",
    "    # plotting\n",
    "    fig, ax = plt.subplots(1,1,figsize=(18,4))\n",
    "    gs      = gridspec.GridSpec(1, 3, width_ratios=[1, 2, 1]) \n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax0.pcolor(W0, cmap=colmap, edgecolors='w', linewidth=0.5)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.set_yticks([])\n",
    "    ax0.invert_yaxis()\n",
    "    ax0.set_title('Ground truth adjacency matrix', size=14)\n",
    "\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    ax1.imshow(TS, cmap=colmap, aspect='auto')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel(\"Time\", size=14)\n",
    "    ax1.set_ylabel(\"Node ID\", size=14)\n",
    "    ax1.set_title(\"Sherrington-Kirkpatrick dynamics\", size=14)\n",
    "\n",
    "    ax2 = plt.subplot(gs[2])\n",
    "    ax2.pcolor(Wr, cmap=colmap, edgecolors='w', linewidth=0.5, \n",
    "               vmax=np.quantile(Wr.flatten(),0.9))\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_title('Reconstructed adjacency matrix', size=14)\n",
    "    ax2.set_xlabel('(via %s)'%recon_name, size=14)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "\n",
    "    if save==True:\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleReconstruction_%s.png\"%recon_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleReconstruction_%s.pdf\"%recon_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)    \n",
    "    \n",
    "    \n",
    "def plot_different_thresholds_recons(G0, TS, recons, \n",
    "                                     recon_name='FreeEnergyMinimization', \n",
    "                                     colmap=plt.cm.Greys,\n",
    "                                     save=True):\n",
    "    \n",
    "    plt.rc('axes', linewidth=2)\n",
    "    R1 = recons[recon_name]\n",
    "\n",
    "    k_avg = np.mean(list(dict(G0.degree()).values()))\n",
    "\n",
    "    fig, ax = plt.subplots(1,4,figsize=(18,4))\n",
    "\n",
    "    Gr = R1.fit(TS, threshold_type='degree', avg_k=6)\n",
    "    Wr = R1.results['weights_matrix']\n",
    "    ax[0].pcolor(Wr, cmap=plt.cm.Greys, edgecolors='w', linewidth=0.2)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title('Reconstructed adjacency matrix', size=13)\n",
    "    ax[0].set_xlabel(r'(no thresholding: raw \"weights_matrix\")', size=12)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "\n",
    "    Gr = R1.fit(TS, threshold_type='range', cutoffs=[(0,1)])\n",
    "    Wr = nx.to_numpy_array(Gr)\n",
    "    ax[1].pcolor(Wr, cmap=plt.cm.Greys, edgecolors='w', linewidth=0.2, \n",
    "                 vmax=np.quantile(Wr.flatten(),0.99))\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].set_title('Reconstructed adjacency matrix', size=13)\n",
    "    ax[1].set_xlabel('(thresholding by range, cutoffs=[(0,1)])', size=12)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    Gr = R1.fit(TS, threshold_type='degree', avg_k=k_avg)\n",
    "    Wr = nx.to_numpy_array(Gr)\n",
    "    ax[2].pcolor(Wr, cmap=plt.cm.Greys, edgecolors='w', linewidth=0.2, \n",
    "                 vmax=np.quantile(Wr.flatten(),0.99))\n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].set_title('Reconstructed adjacency matrix', size=13)\n",
    "    ax[2].set_xlabel(r'(thresholding by $\\langle k \\rangle$ of $G_0$)', size=12)\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "\n",
    "    Gr = R1.fit(TS, threshold_type='quantile', quantile=0.9)\n",
    "    Wr = nx.to_numpy_array(Gr)\n",
    "    ax[3].pcolor(Wr, cmap=plt.cm.Greys, edgecolors='w', linewidth=0.2, \n",
    "                 vmax=np.quantile(Wr.flatten(),0.99))\n",
    "    ax[3].invert_yaxis()\n",
    "    ax[3].set_title('Reconstructed adjacency matrix', size=13)\n",
    "    ax[3].set_xlabel(r'(thresholding by $w_{ij}$ quantile of 0.9)', size=12)\n",
    "    ax[3].set_xticks([])\n",
    "    ax[3].set_yticks([])\n",
    "    \n",
    "    if save==True:\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleReconstruction_thresolding.png\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"ExampleReconstruction_thresolding.pdf\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)\n",
    "    \n",
    "def reconstruct_networks(TS, recons, recon_names, **kwargs):\n",
    "\n",
    "    recons_to_plot = {rec:recons[rec] for rec in recon_names}\n",
    "    Wlist = []\n",
    "\n",
    "    for ri, recon in enumerate(recons_to_plot):\n",
    "        print(dt.datetime.now(),recon)\n",
    "        R1 = recons[recon]\n",
    "        Gr = R1.fit(TS, **kwargs)\n",
    "        Wr = nx.to_numpy_array(Gr)\n",
    "\n",
    "        if recon=='RegularizedCorrelationMatrix':\n",
    "            Gr = R1.fit(TS, num_eigs=3, **kwargs)\n",
    "            Wr = nx.to_numpy_array(Gr)\n",
    "        if recon=='NaiveMeanField':\n",
    "            Gr = R1.fit(TS, exact=False, **kwargs)\n",
    "            Wr = nx.to_numpy_array(Gr)\n",
    "        if recon=='ConvergentCrossMapping':\n",
    "            Gr = R1.fit(TS, **kwargs)\n",
    "            Wr = nx.to_numpy_array(Gr)\n",
    "\n",
    "        Wlist.append(Wr)\n",
    "\n",
    "    return Wlist\n",
    "\n",
    "def plot_all_reconstructions(G0, Wlist, recons, recon_names, width=5,\n",
    "                             colmap=plt.cm.Greys, save=True):\n",
    "\n",
    "\n",
    "    plt.rc('axes', linewidth=2)\n",
    "    \n",
    "    height  = (len(Wlist)+width-1)//width\n",
    "    heights = list(range(height))\n",
    "    widths  = list(range(width))\n",
    "    tups    = [(h,w) for h in heights for w in widths]\n",
    "    \n",
    "    recons_to_plot = {rec:recons[rec] for rec in recon_names}\n",
    "\n",
    "    fi, ax = plt.subplots(height, width, figsize=(20,12.5))\n",
    "    plt.subplots_adjust(wspace=0.125, hspace=0.15)\n",
    "\n",
    "    W0 = nx.to_numpy_array(G0)\n",
    "    ri = 0\n",
    "    q = tups[ri]\n",
    "    ax[q].pcolor(W0, cmap=colmap, edgecolors='w', vmin=0, \n",
    "                 vmax=np.quantile(W0.flatten(),0.9), linewidth=0.1)\n",
    "\n",
    "    ax[q].set_xticks([])\n",
    "    ax[q].set_yticks([])\n",
    "    ax[q].invert_yaxis()\n",
    "    ax[q].set_title('GroundTruth', size=14)\n",
    "\n",
    "    for ri, recon in enumerate(recons_to_plot):\n",
    "        Wr = Wlist[ri]\n",
    "        q  = tups[int(ri+1)]\n",
    "\n",
    "        ax[q].pcolor(Wr, cmap=colmap, edgecolors='w', vmin=0, \n",
    "                     vmax=np.quantile(Wr.flatten(),0.9), linewidth=0.2)\n",
    "        ax[q].invert_yaxis()\n",
    "        ax[q].set_xticks([])\n",
    "        ax[q].set_yticks([])\n",
    "        ax[q].set_title(recon, size=14)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(folder_to_savefigs_to+\"allRecons.png\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"allRecons.pdf\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)\n",
    "    \n",
    "# helper function for the distances\n",
    "def sort_distance_matrix(Dmat, kind='centroid'):\n",
    "    \"\"\"\n",
    "    Takes a matrix of distances between reconstruction methods\n",
    "    and returns an ordering of the matrix that sorts the indices\n",
    "    by closeness.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    Dmat (np.ndarray): the distance matrix in question\n",
    "    kind (str): the type of sorting mechanism to use\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ordering (list): a list of indices sorted by distance to look nice\n",
    "    \n",
    "    \"\"\"\n",
    "    from scipy.spatial.distance import squareform\n",
    "    import scipy.cluster.hierarchy as sch\n",
    "    \n",
    "    condensedD = squareform(Dmat)\n",
    "    Z = sch.linkage(condensedD, method=kind)\n",
    "    \n",
    "    n = len(Z) + 1\n",
    "    cache = dict()\n",
    "    for k in range(len(Z)):\n",
    "        c1, c2 = int(Z[k][0]), int(Z[k][1])\n",
    "        c1 = [c1] if c1 < n else cache.pop(c1)\n",
    "        c2 = [c2] if c2 < n else cache.pop(c2)\n",
    "        cache[n+k] = c1 + c2\n",
    "    \n",
    "    ordering = cache[2*len(Z)]\n",
    "    return ordering\n",
    "\n",
    "# helper function for picky distances\n",
    "def make_connected(G):\n",
    "    \"\"\"\n",
    "    Not a good idea, but if you want this for plotting purposes...\n",
    "    \n",
    "    \"\"\"\n",
    "    S = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "    if len(S)==1:\n",
    "        return G\n",
    "    while len(S)>1:\n",
    "        S = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "        for si,s in enumerate(S):\n",
    "            node_i = np.random.choice(s.nodes())\n",
    "            other_comms = [i for i in range(len(S)) if i!=si]\n",
    "            comm_j = np.random.choice(other_comms)\n",
    "            node_j = np.random.choice(S[comm_j].nodes())\n",
    "            G.add_edge(node_i,node_j)\n",
    "            if nx.is_connected(G):\n",
    "                return G\n",
    "    \n",
    "    return G\n",
    "\n",
    "def specific_distance_all_reconstructions(G0, Wlist, dists,\n",
    "                                          dist_name='QuantumSpectralJSD', \n",
    "                                          stdrdze=True):\n",
    "    \n",
    "    d     = dists[dist_name]\n",
    "    dmat  = np.zeros((len(Wlist),len(Wlist)))\n",
    "\n",
    "    N     = G0.number_of_nodes()\n",
    "    k_avg = np.mean(list(dict(G0.degree()).values()))\n",
    "    p     = k_avg/N\n",
    "    \n",
    "    if stdrdze:\n",
    "        if \"LaplacianSpectral\" not in dist_name:\n",
    "            stdard,_,_ = standardize.mean_GNP_distance(N, p, d.dist)\n",
    "        else:\n",
    "            stdard,_,_ = standardize.mean_GNP_distance(N, p, d)\n",
    "\n",
    "    for i,W1 in enumerate(Wlist):\n",
    "        for j,W2 in enumerate(Wlist):\n",
    "            if i > j:\n",
    "                G1 = nx.from_numpy_array(W1)\n",
    "                G2 = nx.from_numpy_array(W2)\n",
    "\n",
    "                # an especially picky distance\n",
    "                if 'ResistancePerturbation' in dist_name: \n",
    "                    if not nx.is_connected(G1):\n",
    "                        G1 = make_connected(G1)\n",
    "                    if not nx.is_connected(G2):\n",
    "                        G2 = make_connected(G2)\n",
    "                \n",
    "                if \"LaplacianSpectral\" not in dist_name:\n",
    "                    distance_i = d.dist(G1,G2)\n",
    "                else:\n",
    "                    distance_i = d(G1,G2)\n",
    "\n",
    "                if stdrdze:\n",
    "                    dmat[i,j] = distance_i / stdard\n",
    "                    dmat[j,i] = distance_i / stdard\n",
    "\n",
    "                else:\n",
    "                    dmat[i,j] = distance_i\n",
    "                    dmat[j,i] = distance_i\n",
    "    \n",
    "    return dmat\n",
    "\n",
    "def plot_specific_distance_all_reconstructions(dmat, recons, recon_names, \n",
    "                                               abbreviations, \n",
    "                                               dist_name='QuantumSpectralJSD', \n",
    "                                               order=True, colmap=plt.cm.Greys,\n",
    "                                               save=True):\n",
    "    \n",
    "    if order==True:\n",
    "        ordering = sort_distance_matrix(dmat)\n",
    "    else:\n",
    "        ordering = list(range(dmat.shape[0]))\n",
    "    \n",
    "    recons_to_plot = {rec:recons[rec] for rec in recon_names}\n",
    "    dmat_plot = dmat[:,ordering][ordering,:]\n",
    "    \n",
    "    xticks = np.array([abbreviations[i] for i in recons_to_plot.keys()])\n",
    "    yticks = np.array(list(recons_to_plot.keys()))\n",
    "    yticks = np.array([i+\" - \"+abbreviations[i] for i in list(recons_to_plot.keys())])\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "    im = ax.pcolor(dmat_plot, edgecolors='#e6e6e6', linewidth=1.5, cmap=colmap,\n",
    "                   vmax=np.quantile(dmat_plot.flatten(),0.7))\n",
    "    \n",
    "    ax.set_yticks(np.linspace(0.5,dmat_plot.shape[0]-0.5,dmat_plot.shape[0]))\n",
    "    ax.set_yticklabels(yticks[ordering],fontsize=14)\n",
    "    ax.set_xticks(np.linspace(0.5,dmat_plot.shape[0]-0.5,dmat_plot.shape[0]))\n",
    "    ax.set_xticklabels(xticks[ordering],fontsize=14,rotation=90)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_title(dist_name,fontsize=16)\n",
    "\n",
    "    axcolor = fig.add_axes([0.92,0.125,0.035,0.755])\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    axcolor.set_ylabel(r'$D_s(G_1, G_2)$',fontsize=22,rotation=270,labelpad=25)\n",
    "    \n",
    "    if save==True:\n",
    "        plt.savefig(folder_to_savefigs_to+\"Example%s.png\"%dist_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"Example%s.pdf\"%dist_name, \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)\n",
    "    \n",
    "def all_distances_all_reconstructions(G0, Wlist, dists, stdrdze=True):\n",
    "    \n",
    "    dmatlist = []\n",
    "    for name, d in dists.items():\n",
    "        print(dt.datetime.now(),name)\n",
    "        dmat = specific_distance_all_reconstructions(G0, Wlist, \n",
    "                                          dists, dist_name=name, \n",
    "                                          stdrdze=True)\n",
    "        dmatlist.append(dmat)\n",
    "    \n",
    "    return dmatlist\n",
    "\n",
    "def plot_all_distances_all_reconstructions(dmatlist, recons, recon_names, \n",
    "                                           abbreviations, width=4,\n",
    "                                           single_order=True, colmap=plt.cm.Greys,\n",
    "                                           save=True):\n",
    "    \n",
    "    plt.rc('axes', linewidth=2)\n",
    "    height  = (len(dmatlist)+width-1)//width\n",
    "    heights = list(range(height))\n",
    "    widths  = list(range(width))\n",
    "    tups    = [(h,w) for h in heights for w in widths]\n",
    "\n",
    "    recons_to_plot = {rec:recons[rec] for rec in recon_names}\n",
    "        \n",
    "    fig, ax = plt.subplots(height, width, figsize=(34,30))\n",
    "    plt.subplots_adjust(wspace=0.125, hspace=0.275)\n",
    "\n",
    "    for di in range(len(dmatlist)):\n",
    "        q = tups[di]\n",
    "        D = dmatlist[di]\n",
    "\n",
    "        xticks = np.array([abbreviations[i] for i in recons_to_plot.keys()])\n",
    "        yticks = np.array([i for i in list(recons_to_plot.keys())])\n",
    "        yticks = np.array([i+\" - \"+abbreviations[i] for i in yticks])\n",
    "\n",
    "        D = np.nan_to_num(D)\n",
    "        \n",
    "        if single_order==True:\n",
    "            if di==0:\n",
    "                ordering = sort_distance_matrix(D)\n",
    "                ordering = ordering[::-1]\n",
    "        else:\n",
    "            ordering = sort_distance_matrix(D)\n",
    "            ordering = ordering[::-1]\n",
    "            \n",
    "        dmat_plot = D[:,ordering][ordering,:]\n",
    "\n",
    "        im = ax[q].pcolor(dmat_plot, edgecolors='#e6e6e6', linewidth=1.5, cmap=colmap,\n",
    "                   vmax=np.quantile(dmat_plot.flatten(),0.725))\n",
    "\n",
    "        if q[1]!=0:\n",
    "            yticks = xticks.copy()\n",
    "\n",
    "        ax[q].set_yticks(np.linspace(0.5,len(yticks)-0.5,len(yticks)))\n",
    "        ax[q].set_yticklabels(yticks[ordering],fontsize=18)\n",
    "        ax[q].set_xticks(np.linspace(0.5,len(xticks)-0.5,len(xticks)))\n",
    "        ax[q].set_xticklabels(xticks[ordering],fontsize=18,rotation=90)\n",
    "        ax[q].invert_yaxis()\n",
    "        ax[q].set_title(list(dists.keys())[di], size=26)\n",
    "\n",
    "        fig.colorbar(im, ax=ax[q])\n",
    "        if q[1]==widths[-1]:\n",
    "            ax[q].set_ylabel(r'$D_s(G_1,G_2)$', rotation=270, labelpad=95, fontsize=22)\n",
    "            ax[q].yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    if save:\n",
    "        if single_order:\n",
    "            plt.savefig(folder_to_savefigs_to+\"allDists_singleSort.png\", \n",
    "                        dpi=425, bbox_inches='tight')\n",
    "            plt.savefig(folder_to_savefigs_to+\"allDists_singleSort.pdf\", \n",
    "                        dpi=425, bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(folder_to_savefigs_to+\"allDists_multiSort.png\", \n",
    "                        dpi=425, bbox_inches='tight')\n",
    "            plt.savefig(folder_to_savefigs_to+\"allDists_multiSort.pdf\", \n",
    "                        dpi=425, bbox_inches='tight')\n",
    "            \n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)    \n",
    "    \n",
    "def example_G1G2_alldistances(G1, G2, dists, save=True):\n",
    "    col_width = max(len(word) for word in dists.keys()) + 1  \n",
    "    num = 1\n",
    "    example_distances = []\n",
    "\n",
    "    for name, d in dists.items():\n",
    "        if \"LaplacianSpectral\" in name:\n",
    "            distance_i = d(G1,G2)\n",
    "        else:\n",
    "            distance_i = d.dist(G1,G2)\n",
    "\n",
    "        print(\"\\t%02i\"%num, \"\".join(name.ljust(col_width)),distance_i)\n",
    "\n",
    "        example_distances.append(distance_i)\n",
    "        num += 1\n",
    "        \n",
    "    plt.rc('axes', linewidth=2)\n",
    "    plt.rc('axes', axisbelow=True)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(21,5))\n",
    "    plt.subplots_adjust(wspace=0.075, hspace=0.195)\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 5, width_ratios=[2.5, 2.5, 0.25, 4, 1]) \n",
    "\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    pos1 = nx.kamada_kawai_layout(G1)\n",
    "    nx.draw_networkx_nodes(G1, pos1, node_size=75, node_color='w', \n",
    "                           linewidths=2, edgecolors=\"#333333\", ax=ax1)\n",
    "    nx.draw_networkx_edges(G1, pos1, width=2, edge_color=\"#333333\", \n",
    "                           alpha=0.9, ax=ax1)\n",
    "    ax1.set_title(r\"$G_1$\",fontsize=16)\n",
    "    ax1.set_axis_off()\n",
    "\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    pos2 = nx.kamada_kawai_layout(G2)\n",
    "    nx.draw_networkx_nodes(G2, pos2, node_size=75, node_color='w', \n",
    "                           linewidths=2, edgecolors=\"#333333\", ax=ax2)\n",
    "    nx.draw_networkx_edges(G2, pos2, width=2, edge_color=\"#333333\", \n",
    "                           alpha=0.9, ax=ax2)\n",
    "    ax2.set_title(r\"$G_2$\",fontsize=16)\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    ax3 = plt.subplot(gs[3])\n",
    "    barwidth = 0.75\n",
    "    barx = list(range(len(example_distances)))\n",
    "    ax3.bar(barx, example_distances, width=barwidth, color='w', \n",
    "            edgecolor='#333333', linewidth=3.0)\n",
    "\n",
    "    xlabels = list(dists.keys())\n",
    "    xlabels = [\"%02i: \"%(i+1) + name for i, name in enumerate(xlabels)]\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.set_xlim(-barwidth, max(barx)+barwidth)\n",
    "    ax3.set_xticks(barx)\n",
    "    ax3.set_xticklabels([\"%02i\"%(i+1) for i in barx], fontsize=14)\n",
    "    ax3.set_ylabel(r\"$D(G_1, G_2)_d$\", fontsize=16)\n",
    "    ax3.grid(linewidth=2.5, color='#999999', alpha=0.5)\n",
    "    ax3.set_title(\"Several distances from netrd (log-scaled)\",fontsize=16)\n",
    "\n",
    "    ax4 = plt.subplot(gs[4])\n",
    "    x = 0\n",
    "    textys = np.linspace(1,0,len(barx))\n",
    "    for i, y in enumerate(textys):\n",
    "        ax4.text(x,y,xlabels[i],fontsize=13)\n",
    "    ax4.set_ylim(0,1.05)\n",
    "    ax4.set_axis_off()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(folder_to_savefigs_to+\"Example_AllDistances_G1G2.png\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "        plt.savefig(folder_to_savefigs_to+\"Example_AllDistances_G1G2.pdf\", \n",
    "                    dpi=425, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.rc('axes', linewidth=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0: Introduction to dynamics used to generate time series data in `netrd`\n",
    "\n",
    "Note: these are not all of the methods for simulating dynamics that are implemented in `netrd`, but they will be used in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics = {'BranchingModel':              netrd.dynamics.BranchingModel(),\n",
    "            'IsingGlauber':                netrd.dynamics.IsingGlauber(),\n",
    "            'SherringtonKirkpatrickIsing': netrd.dynamics.SherringtonKirkpatrickIsing(),\n",
    "            'VoterModel':                  netrd.dynamics.VoterModel()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: First, create an example ground truth network and simulate dynamics on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyna_name = 'SherringtonKirkpatrickIsing'\n",
    "# dyna_name = 'BranchingModel'\n",
    "# dyna_name = 'IsingGlauber'\n",
    "# dyna_name = 'VoterModel'\n",
    "\n",
    "L  = 2001\n",
    "N  = 64\n",
    "ncliques = 4\n",
    "\n",
    "G0 = nx.ring_of_cliques(ncliques,int(N/ncliques))\n",
    "D1 = dynamics[dyna_name]\n",
    "TS = D1.simulate(G0,L)\n",
    "\n",
    "k_avg = np.mean(list(dict(G0.degree()).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_groundtruth_timeseries_adjmat(G0,TS,dyna_name,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/ExampleGroundTruth_SherringtonKirkpatrickIsing.png\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0: Introduction to the network reconstruction methods used in `netrd`\n",
    "\n",
    "Note: these are not all of the reconstruction methods implemented in `netrd`, but they will be used in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = {\n",
    "'ConvergentCrossMapping':       netrd.reconstruction.ConvergentCrossMapping(),\n",
    "'CorrelationMatrix':            netrd.reconstruction.CorrelationMatrix(),\n",
    "'ExactMeanField':               netrd.reconstruction.MeanField(),\n",
    "'FreeEnergyMinimization':       netrd.reconstruction.FreeEnergyMinimization(),\n",
    "'GraphicalLasso':               netrd.reconstruction.GraphicalLasso(),\n",
    "'MarchenkoPastur':              netrd.reconstruction.MarchenkoPastur(),\n",
    "'MaximumLikelihoodEstimation':  netrd.reconstruction.MaximumLikelihoodEstimation(),\n",
    "'MutualInformationMatrix':      netrd.reconstruction.MutualInformationMatrix(),\n",
    "'NaiveMeanField':               netrd.reconstruction.MeanField(),\n",
    "'OUInference':                  netrd.reconstruction.OUInference(),\n",
    "'ThoulessAndersonPalmer':       netrd.reconstruction.ThoulessAndersonPalmer(),\n",
    "'PartialCorrelationMatrix':     netrd.reconstruction.PartialCorrelationMatrix(),\n",
    "'NaiveTransferEntropy':         netrd.reconstruction.NaiveTransferEntropy(), # expensive \n",
    "'RegularizedCorrelationMatrix': netrd.reconstruction.CorrelationMatrix()}\n",
    "\n",
    "recon_names = list(recons.keys())\n",
    "\n",
    "abbreviations = {\n",
    "'ConvergentCrossMapping':       \"rCCM\",\n",
    "'CorrelationMatrix':            \"rCOR\",\n",
    "'ExactMeanField':               \"rEMF\",\n",
    "'FreeEnergyMinimization':       \"rFEM\",\n",
    "'GraphicalLasso':               \"rGLA\",\n",
    "'MarchenkoPastur':              \"rMAR\",\n",
    "'MaximumLikelihoodEstimation':  \"rMLE\",\n",
    "'MutualInformationMatrix':      \"rMUT\",\n",
    "'NaiveMeanField':               \"rNMF\",\n",
    "'OUInference':                  \"rOUI\",\n",
    "'ThoulessAndersonPalmer':       \"rTAP\",\n",
    "'PartialCorrelationMatrix':     \"rPCM\",\n",
    "'PartialCorrelationInfluence':  \"rPCI\",\n",
    "'NaiveTransferEntropy':         \"rTRE\", \n",
    "'RegularizedCorrelationMatrix': \"rREG\",\n",
    "'GrangerCausality':             \"rGRA\",\n",
    "'CorrelationSpanningTree':      \"rMST\",\n",
    "'OptimalCausationEntropy':      \"rOCE\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: One example reconstruction method: Free Energy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_name = 'FreeEnergyMinimization'\n",
    "colmap = plt.cm.Greys\n",
    "plot_adjmat_timeseries_recon(G0, TS, recons, recon_name, colmap, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/ExampleReconstruction_FreeEnergyMinimization.png\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1: The `R1` object has a `R1.results` dictionary, which contains the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1 = recons[recon_name]\n",
    "Gr = R1.fit(TS, threshold_type='degree', avg_k=k_avg)\n",
    "\n",
    "print(R1.results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2: We often use the `netrd.utilities.threshold` when comparing reconstructions\n",
    "Below are some options for how to threshold the reconstruction (the default in this notebook will be to threshold by the average degree of the ground truth network. **Note:** we rarely have enough information to ever justify this, but for explanatory purposes it is useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_name = 'FreeEnergyMinimization'\n",
    "colmap = plt.cm.Greys\n",
    "plot_different_thresholds_recons(G0, TS, recons, recon_name, colmap, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/ExampleReconstruction_thresolding.png\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Now reconstruct _many_ time networks from the time series above (takes ~6min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_avg = np.mean(list(dict(G0.degree()).values()))\n",
    "Wlist = reconstruct_networks(TS, recons, recon_names, threshold_type='degree', avg_k=k_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = plt.cm.Greys\n",
    "plot_width = 5\n",
    "plot_all_reconstructions(G0, Wlist, recons, recon_names, plot_width, colmap, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/allRecons.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0: Introduction to the graph distances in `netrd`\n",
    "\n",
    "Note: these are not all of the distances implemented in `netrd`, but they will be used in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = {\n",
    "\"JaccardDistance\":         netrd.distance.JaccardDistance(), \n",
    "\"Hamming\":                 netrd.distance.Hamming(), \n",
    "\"HammingIpsenMikhailov\":   netrd.distance.HammingIpsenMikhailov(), \n",
    "\"Frobenius\":               netrd.distance.Frobenius(), \n",
    "\"PolynomialDissimilarity\": netrd.distance.PolynomialDissimilarity(), \n",
    "\"PortraitDivergence\":      netrd.distance.PortraitDivergence(), \n",
    "\"OnionDivergence\":         netrd.distance.OnionDivergence(), \n",
    "\"QuantumSpectralJSD\":      netrd.distance.QuantumJSD(), \n",
    "\"DegreeDivergence\":        netrd.distance.DegreeDivergence(), \n",
    "\"ResistancePerturbation\":  netrd.distance.ResistancePerturbation(), \n",
    "\"NetLSD\":                  netrd.distance.NetLSD(), \n",
    "\"CommunicabilitySequence\": netrd.distance.CommunicabilityJSD(),\n",
    "\"IpsenMikhailov\":          netrd.distance.IpsenMikhailov(), \n",
    "\"NonBacktrackingSpectral\": netrd.distance.NonBacktrackingSpectral(), \n",
    "\"NetSimile\":               netrd.distance.NetSimile(), \n",
    "\"DeltaCon\":                netrd.distance.DeltaCon()}\n",
    "\n",
    "dist_names = list(dists.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Example case: measure (many) graph distance(s) between two BA networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 2\n",
    "G1 = nx.barabasi_albert_graph(n,m)\n",
    "G2 = nx.barabasi_albert_graph(n,m)\n",
    "print(\"Two BA networks with n=%i and m=%i are the following distances apart:\\n\"%(n,m))\n",
    "\n",
    "example_G1G2_alldistances(G1, G2, dists, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/Example_AllDistances_G1G2.png\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Let's look at the distances between the reconstructions under one distance measure..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...but first: an introduction to the we often `standardize` function for distances in netrd\n",
    "\n",
    "It is difficult to meaningully compare *across* distances, which is why we have introduced the standardized distance here. This means that the standardized distance (under distance, $d$) between $G_1$ and $G_2$ is expressed as follows:\n",
    "\n",
    "$$D_s(G_1,G_2)_d = \\dfrac{D(G_1,G_2)_d}{\\langle D(G_{(n,p)},G'_{(n,p)})_d\\rangle}$$\n",
    "\n",
    "This means: we divide by the expected **mean within-ensemble graph distance** between pairs of graph randomly sampled from $G(n,p)$, where $n$ and $p$ correspond to the density and size of the graph in question. \n",
    "\n",
    "The command to standardize distances is below as `standardize.mean_GNP_distance(N, p, distance_measure)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3: One example distance to focus on: the quantum spectral Jensen-Shannon divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_name='QuantumSpectralJSD'\n",
    "dmat = specific_distance_all_reconstructions(G0, Wlist, dists, dist_name, stdrdze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order  = True\n",
    "colmap = plt.cm.Greys\n",
    "save   = True\n",
    "plot_specific_distance_all_reconstructions(dmat, recons, recon_names, abbreviations, \n",
    "                                           dist_name, order, colmap, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/ExampleQuantumSpectralJSD.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4: Now, let's calculate all of the distances between all of the reconstructions (~2min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatlist = all_distances_all_reconstructions(G0, Wlist, dists, stdrdze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1: Plotting with a common sorting of the distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4\n",
    "single_order = True\n",
    "colmap = plt.cm.Greys\n",
    "save = True\n",
    "plot_all_distances_all_reconstructions(dmatlist, recons, recon_names, abbreviations, \n",
    "                                       width, single_order, colmap, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/allDists_singleSort.png\" style=\"height:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2: Plotting without common sorting of the distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4\n",
    "single_order = False\n",
    "colmap = plt.cm.Greys\n",
    "save = True\n",
    "plot_all_distances_all_reconstructions(dmatlist, recons, recon_names, abbreviations, \n",
    "                                       width, single_order, colmap, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_figures/allDists_multiSort.png\" style=\"height:800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate goal is to develop a systematic understanding of network reconstruction techniques and graph distance measures using plots like the ones above. They correspond to techniques that are likely to generate *close* networks, and from that we will develop a better understanding about which methods to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this `netrd` introduction. \n",
    "\n",
    "### Resources:\n",
    "- __[Visit the github](https://github.com/netsiphd/netrd)__\n",
    "- __[Visit the ReadTheDocs](https://netrd.readthedocs.io/en/latest/)__\n",
    "- __[Visit the netrdExplorer website](https://netrdexplorer.herokuapp.com/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
